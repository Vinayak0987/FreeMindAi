#!/usr/bin/env python3
"""
Simple test to verify the Kaggle ‚Üí Processing ‚Üí Training pipeline works through the API.
"""

import requests
import json
import time

def test_kaggle_to_training_pipeline():
    """Test the complete pipeline: Kaggle download ‚Üí Processing ‚Üí Training"""
    
    print("üöÄ TESTING COMPLETE KAGGLE ‚Üí PROCESSING ‚Üí TRAINING PIPELINE")
    print("=" * 70)
    
    url = "http://localhost:5001/process"
    
    # Test different datasets
    test_cases = [
        {
            'name': 'Iris Classification',
            'task_type': 'classification',
            'text_prompt': 'iris dataset'
        },
        {
            'name': 'Titanic Dataset', 
            'task_type': 'classification',
            'text_prompt': 'titanic dataset'
        }
    ]
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\nüìä TEST {i}: {test_case['name']}")
        print("-" * 40)
        print(f"Task Type: {test_case['task_type']}")
        print(f"Query: '{test_case['text_prompt']}'")
        
        try:
            print("\nüîÑ Sending request...")
            response = requests.post(url, data=test_case, timeout=300)
            
            if response.status_code != 200:
                print(f"‚ùå HTTP Error: {response.status_code}")
                print(f"Response: {response.text[:200]}...")
                continue
            
            result = response.json()
            
            # Check for error
            if 'error' in result:
                print(f"‚ùå API Error: {result['error']}")
                continue
            
            # Check for successful processing
            if not result.get('success', False):
                print("‚ùå Processing failed")
                continue
            
            # Extract key information
            total_samples = result.get('totalSamples', 'N/A')
            features = result.get('features', 'N/A')
            task_type = result.get('task_type', 'N/A')
            
            # Model information
            model_info = result.get('model_info', {})
            model_name = model_info.get('model_name', 'N/A')
            model_score = model_info.get('score', 'N/A')
            
            # Data analysis
            data_analysis = result.get('data_analysis', {})
            column_names = data_analysis.get('column_names', [])
            
            print("‚úÖ SUCCESS! Pipeline completed successfully")
            print(f"üìä Dataset: {total_samples} samples, {features} features")
            print(f"üéØ Task Type: {task_type}")
            print(f"üèÜ Best Model: {model_name}")
            print(f"üìà Model Score: {model_score}")
            
            if column_names:
                print(f"üìã Columns: {column_names[:5]}{'...' if len(column_names) > 5 else ''}")
            
            # Check if download is available
            download_url = result.get('download_url')
            if download_url:
                print(f"üíæ Model Download: Available ({download_url})")
            
            # Additional verification checks
            verification_score = 0
            total_checks = 5
            
            if isinstance(total_samples, int) and total_samples > 0:
                verification_score += 1
                print("‚úì Real dataset loaded")
            
            if isinstance(features, int) and features > 0:
                verification_score += 1
                print("‚úì Features extracted")
            
            if model_name != 'N/A' and model_name:
                verification_score += 1
                print("‚úì Model trained")
            
            if isinstance(model_score, (int, float)) and model_score > 0:
                verification_score += 1
                print("‚úì Model evaluated")
            
            if download_url:
                verification_score += 1
                print("‚úì Artifacts generated")
            
            print(f"\nüéØ Verification: {verification_score}/{total_checks} checks passed")
            
            if verification_score >= 4:
                print("üéâ EXCELLENT: Full pipeline working!")
            elif verification_score >= 3:
                print("üëç GOOD: Core pipeline working!")
            else:
                print("‚ö†Ô∏è LIMITED: Some issues detected")
                
        except requests.exceptions.Timeout:
            print("‚ùå Request timed out (>5 minutes)")
        except requests.exceptions.ConnectionError:
            print("‚ùå Could not connect to API")
            print("üí° Make sure Flask app is running: python project/new/app.py")
        except Exception as e:
            print(f"‚ùå Unexpected error: {e}")
    
    print("\n" + "="*70)
    print("‚úÖ PIPELINE VERIFICATION COMPLETE")
    print(
        "\nIf you see 'SUCCESS' messages above, your Kaggle ‚Üí Processing ‚Üí Training "
        "pipeline is working correctly!"
    )
    print("\nüí° The system can now:")
    print("   ‚Ä¢ Download datasets from Kaggle")
    print("   ‚Ä¢ Process and analyze the data")
    print("   ‚Ä¢ Train machine learning models")
    print("   ‚Ä¢ Generate downloadable model artifacts")

if __name__ == "__main__":
    test_kaggle_to_training_pipeline()
